---
id: DTL-028
title: "Add comprehensive tests for cross-entity metrics"
type: testing
status: ready
labels:
  - stack:backend
  - type:testing
  - priority:medium
  - state:has-strategy
  - state:has-spec
parent: DTL-022
created: 2025-11-18T00:00:00Z
updated: 2025-11-18T00:00:00Z
---

# DTL-028: Add comprehensive tests for cross-entity metrics

## Description

Implement unit, integration, and golden tests for cross-entity metric generation covering all metric types, validation scenarios, and edge cases.

## What needs to be built

### Unit Tests

**Metric Schema Tests** (`src/tests/unit/test_schemas.py`):
- Test Metric model validation (all types: simple, ratio, derived, conversion)
- Test primary_entity property extraction from meta block
- Test MetricTypeParams variants (SimpleMetricParams, RatioMetricParams, etc.)
- Test validation edge cases (invalid type, mismatched params, missing fields)
- Test MetricReference model

**Metric Parser Tests** (`src/tests/unit/test_dbt_metric_parser.py`):
- Test parse_file for each metric type
- Test parse_directory with multiple files and nested directories
- Test primary entity resolution (explicit, inferred from denominator, error cases)
- Test dependency extraction for each metric type
- Test error handling (invalid YAML, missing required fields, unknown metric type)
- Test nested directories and file discovery
- Test validation integration with semantic models

**Measure Generation Tests** (`src/tests/unit/test_lookml_generator.py`):
- Test `_generate_metric_measure()` for each metric type
- Test SQL generation (simple, ratio, derived)
- Test `_extract_required_fields()` with various scenarios
- Test cross-view reference formatting (`${view.measure}`)
- Test view prefix handling
- Test measure metadata (labels, descriptions, value formats)
- Test metric ownership filtering (only owned metrics in view)

**Explore Enhancement Tests** (`src/tests/unit/test_lookml_generator.py`):
- Test `_identify_metric_requirements()` with various metrics
- Test join fields without metrics (dimensions_only only)
- Test join fields with one metric requiring one measure
- Test join fields with multiple metrics requiring multiple measures
- Test that base view measures are excluded from required_fields
- Test no duplicate measures in fields list
- Test view prefix handling in fields
- Test deterministic output (sorted fields)

**Validation Tests** (`src/tests/unit/test_validation.py`):
- Test `build_join_graph()` with various model structures
- Test entity connectivity validation (valid, unreachable, multi-hop)
- Test error messages for common issues
- Test primary entity validation (exists, doesn't exist)
- Test measure existence validation
- Test max hop limit enforcement

### Integration Tests

**End-to-End Metric Generation** (`src/tests/integration/test_cross_entity_metrics.py`):

Create comprehensive integration tests covering:

1. **Basic ratio metric**:
   - Semantic models: searches, rental_orders
   - Metric: search_conversion_rate (ratio)
   - Verify generated measure in searches.view.lkml
   - Verify required_fields present
   - Verify join fields expose rental_count

2. **Multi-entity derived metric**:
   - Semantic models: users, searches, rental_orders
   - Metric: engagement_score (derived)
   - Verify generated measure in users.view.lkml
   - Verify required_fields includes both searches and rental measures
   - Verify both joins expose required measures

3. **Simple metric cross-view**:
   - Semantic models: users, rental_orders
   - Metric: total_revenue (simple, but owned by users)
   - Verify cross-view reference
   - Verify required_fields

4. **Validation error scenarios**:
   - Unreachable measure
   - Missing primary_entity
   - Invalid primary_entity name
   - Missing measure reference

**Test Flow**:
```python
def test_search_conversion_rate_generation():
    # Arrange
    parser = DbtParser()
    metric_parser = DbtMetricParser()

    models = parser.parse_directory("fixtures/semantic_models")
    metrics = metric_parser.parse_directory("fixtures/metrics")

    generator = LookMLGenerator()

    # Act
    output = generator.generate(models, metrics=metrics)

    # Assert
    searches_view = output["searches.view.lkml"]

    # Verify measure exists
    assert "measure: search_conversion_rate" in searches_view

    # Verify required_fields
    assert "required_fields: [rental_orders.rental_count]" in searches_view

    # Verify SQL
    assert "${rental_orders.rental_count}" in searches_view
    assert "/ NULLIF(${search_count}, 0)" in searches_view

    # Verify explore
    explores = output["explores.lkml"]
    assert "rental_orders.rental_count" in explores
```

### Golden Tests

**Expected Output Files** (`src/tests/golden/`):
- `expected_searches_with_metrics.view.lkml`: Searches view with cross-entity measure
- `expected_users_with_metrics.view.lkml`: Users view with multi-entity metric
- `expected_explores_with_metrics.lkml`: Explores with enhanced join fields

Compare generated output against golden files byte-for-byte.

### Test Fixtures

**Semantic Models** (`src/tests/fixtures/semantic_models/`):
- `sem_rental_orders.yml`: Fact table with measures (rental_count, total_revenue)
- `sem_searches.yml`: Fact table with measures (search_count) and foreign key to users
- `sem_users.yml`: Dimension table with measures (user_count)

**Metrics** (`src/tests/fixtures/metrics/`):
- `search_conversion.yml`: Ratio metric (search as primary)
- `revenue_per_user.yml`: Ratio metric (user as primary)
- `engagement_score.yml`: Derived metric with 3 entities
- `total_revenue.yml`: Simple metric

### Coverage Target

- **Overall**: 95%+ branch coverage
- **New code**: 100% coverage (schemas, parser, generator, validation)
- **All metric types tested**: simple, ratio, derived
- **All error paths tested**: validation errors, parsing errors
- **All validation scenarios tested**: connectivity, existence, reachability

## Why it's needed (connection to epic)

Ensures cross-entity metric feature works correctly, maintains quality standards, and prevents regressions. Without comprehensive tests, we risk shipping broken or incomplete functionality.

## Technical scope from labels

Testing work in `src/tests/`:
- Unit tests in `unit/` directory
- Integration tests in `integration/` directory
- Golden tests in `test_golden.py`
- Test fixtures in `fixtures/` directory
- Follow existing test patterns (arrange-act-assert)
- Use pytest fixtures appropriately

## Acceptance Criteria

- [ ] All unit tests implemented and passing
- [ ] All integration tests implemented and passing
- [ ] Golden tests created with expected output files
- [ ] Test fixtures created (semantic models + metrics)
- [ ] Coverage target met (95%+ overall, 100% new code)
- [ ] All metric types covered in tests
- [ ] All validation scenarios covered in tests
- [ ] All error paths tested
- [ ] Tests follow existing patterns and conventions
- [ ] Clear test names describing what is tested

## Testing requirements

**Test organization**:
- Group tests by functionality (schemas, parser, generator, validation)
- Use descriptive test class names (TestMetricSchemas, TestMetricParser, etc.)
- Use descriptive test method names (test_ratio_metric_sql_generation)
- Follow arrange-act-assert pattern
- Use pytest fixtures for common setup

**Test quality**:
- Each test should test ONE thing
- Tests should be independent (no shared state)
- Use clear assertions with helpful error messages
- Mock external dependencies appropriately
- Don't test implementation details, test behavior

**Coverage**:
- Run with `make test-coverage`
- Generate HTML coverage report
- Identify and add tests for uncovered branches
- Aim for 100% coverage of new code

## Dependencies

- DTL-023 (test metric schemas)
- DTL-024 (test metric parser)
- DTL-025 (test measure generation)
- DTL-026 (test explore enhancement)
- DTL-027 (test validation)

## Blocked by

- DTL-023
- DTL-024
- DTL-025
- DTL-026
- DTL-027

## Blocks

- None (testing is final step)

## Links
- Epic: [DTL-022](./../epics/DTL-022.md)
- Depends on: All other issues in epic
- Implementation plan: .tasks/plans/cross-entity-metrics-plan.yaml
- Implementation strategy: [DTL-028-strategy.md](./../strategies/DTL-028-strategy.md)
- Implementation spec: [DTL-028-spec.md](./../specs/DTL-028-spec.md)

## Notes

### Test Fixture Structure

```
src/tests/fixtures/
├── semantic_models/
│   ├── sem_rental_orders.yml
│   ├── sem_searches.yml
│   └── sem_users.yml
└── metrics/
    ├── search_conversion.yml
    ├── revenue_per_user.yml
    ├── engagement_score.yml
    └── total_revenue.yml
```

### Example Test Cases

**Ratio metric test**:
```python
def test_ratio_metric_generates_correct_sql():
    metric = RatioMetric(
        name="conversion_rate",
        type_params=RatioMetricParams(
            numerator="rental_count",
            denominator="search_count"
        ),
        meta={"primary_entity": "search"}
    )

    generator = LookMLGenerator()
    sql = generator._generate_ratio_sql(metric, models)

    assert sql == "1.0 * ${rental_orders.rental_count} / NULLIF(${search_count}, 0)"
```

**Required fields test**:
```python
def test_extract_required_fields_excludes_same_view():
    metric = RatioMetric(
        name="conversion_rate",
        type_params=RatioMetricParams(
            numerator="rental_count",     # From other view
            denominator="search_count"    # From same view (searches)
        )
    )

    searches_model = find_model("searches", models)

    required = generator._extract_required_fields(
        metric, searches_model, models
    )

    assert required == ["rental_orders.rental_count"]
    assert "search_count" not in str(required)
```

### Golden Test Pattern

```python
def test_searches_with_metrics_matches_golden():
    models = parse_semantic_models("fixtures/semantic_models")
    metrics = parse_metrics("fixtures/metrics")

    generator = LookMLGenerator()
    output = generator.generate(models, metrics=metrics)

    generated = output["searches.view.lkml"]

    with open("tests/golden/expected_searches_with_metrics.view.lkml") as f:
        expected = f.read()

    assert generated == expected, "Generated output doesn't match golden file"
```

## History
### 2025-11-18 00:00 - Issue Created
Created from epic DTL-022
