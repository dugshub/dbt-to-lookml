epic:
  title: "Epic: Implement Cross-Entity Metrics Support"
  description: |
    ## Problem Statement

    dbt semantic layer defines metrics that can span multiple entities (semantic models). For example:
    - `search_conversion_rate = rental_count / search_count` combines measures from rental_orders and searches
    - `revenue_per_user = total_revenue / user_count` combines measures from rental_orders and users

    Currently, dbt-to-lookml only converts semantic models to LookML views. Metrics that span multiple entities cannot be represented in the generated LookML.

    ## Solution Approach

    Implement metric parsing and generation with **primary entity ownership** pattern:

    1. **Parse dbt metrics** from `metrics/*.yml` files with `meta.primary_entity` declaration
    2. **Assign metric ownership** to the appropriate semantic model/explore based on primary entity
    3. **Generate cross-view measures** in the primary entity's view file using `${other_view.measure}` references
    4. **Use required_fields** parameter to auto-activate joins when cross-entity metrics are selected
    5. **Expose required measures** in join definitions via selective fields parameter
    6. **Validate connectivity** to ensure all required measures are reachable via join graph

    ### Key Principle: Primary Entity Ownership

    Every metric has a **primary entity** that determines:
    - Which view file contains the generated measure
    - Which explore serves as the base/spine for the calculation
    - What the "universe" of the denominator represents

    Example:
    ```yaml
    metrics:
      - name: search_conversion_rate
        type: ratio
        type_params:
          numerator: rental_count    # From rental_orders
          denominator: search_count  # From searches
        meta:
          primary_entity: search     # Searches is the spine (need full search universe)
    ```

    Generated in `searches.view.lkml`:
    ```lookml
    measure: search_conversion_rate {
      type: number
      sql: 1.0 * ${rental_orders.rental_count} / NULLIF(${search_count}, 0) ;;
      required_fields: [rental_orders.rental_count]
    }
    ```

    ## Success Criteria

    - [ ] Parser successfully reads dbt metric YAML files
    - [ ] Metrics with explicit `meta.primary_entity` generate in correct view
    - [ ] Metrics without explicit primary_entity infer from denominator (ratio type)
    - [ ] Generated measures use `required_fields` for automatic join activation
    - [ ] Explore join definitions expose required measures
    - [ ] Validation detects unreachable measures and provides clear errors
    - [ ] All tests pass with 95%+ branch coverage
    - [ ] Integration tests verify end-to-end metric generation
    - [ ] Documentation explains primary entity ownership pattern

    ## Technical Architecture

    ### New Components

    1. **Metric Schema Models** (`schemas.py`)
       - `Metric` base model with type variants
       - `SimpleMetric`, `RatioMetric`, `DerivedMetric`, `ConversionMetric`
       - Meta block parsing for primary_entity

    2. **Metric Parser** (`parsers/dbt_metrics.py`)
       - Parse `metrics/*.yml` files
       - Extract measure dependencies
       - Resolve primary entity (explicit or inferred)

    3. **Cross-Entity Measure Generator** (`generators/lookml.py`)
       - Generate measures with cross-view references
       - Add `required_fields` parameter
       - Validate entity connectivity via join graph

    4. **Explore Enhancer** (`generators/lookml.py`)
       - Update join `fields` parameter to expose required measures
       - Maintain `dimensions_only*` for non-required measures

    ### Modified Components

    1. **CLI** (`__main__.py`)
       - Add `--metrics-dir` parameter (default: `metrics/`)
       - Parse metrics in addition to semantic models

    2. **LookMLGenerator** (`generators/lookml.py`)
       - Accept metrics as input
       - Integrate cross-entity measures into view generation
       - Update explore generation to handle metric requirements

    ## Sub-Issues

    1. Add Metric schema models (foundation)
    2. Implement dbt metrics parser (parsing layer)
    3. Add cross-entity measure generation (generation layer)
    4. Update explore generation for metric requirements (generation layer)
    5. Add entity connectivity validation (validation layer)
    6. Add comprehensive tests (testing layer)

  labels:
    - stack:backend
    - type:epic
    - priority:high
  status: Refinement

  children:
    - title: "Add Metric schema models to schemas.py"
      description: |
        Extend Pydantic schema models to support dbt metrics with all metric types and metadata.

        ## What needs to be built

        ### New Models

        **Base Metric Model**:
        ```python
        class Metric(BaseModel):
            name: str
            type: Literal["simple", "ratio", "derived", "conversion"]
            type_params: MetricTypeParams
            label: str | None = None
            description: str | None = None
            meta: dict[str, Any] | None = None

            @property
            def primary_entity(self) -> str | None:
                """Extract primary_entity from meta block."""
                if self.meta:
                    return self.meta.get("primary_entity")
                return None
        ```

        **Type-Specific Params**:
        ```python
        class SimpleMetricParams(BaseModel):
            measure: str

        class RatioMetricParams(BaseModel):
            numerator: str
            denominator: str

        class DerivedMetricParams(BaseModel):
            expr: str
            metrics: list[MetricReference]

        class ConversionMetricParams(BaseModel):
            conversion_type_params: dict[str, Any]

        MetricTypeParams = Union[SimpleMetricParams, RatioMetricParams, DerivedMetricParams, ConversionMetricParams]
        ```

        **Helper Models**:
        ```python
        class MetricReference(BaseModel):
            name: str
            alias: str | None = None
            offset_window: str | None = None
        ```

        ### Validation

        - All metric names must be globally unique
        - Type params must match metric type
        - Primary entity (if specified) must reference valid entity name
        - Measure references must exist in semantic models

        ## Why it's needed

        Foundation for parsing dbt metric files and generating cross-entity LookML measures.

        ## Technical scope

        Backend work in `src/dbt_to_lookml/schemas.py`:
        - Add new Pydantic models with full type hints (mypy --strict)
        - Follow existing schema patterns (BaseModel, Optional fields)
        - Add helper methods for extracting dependencies

        ## Testing requirements

        - Unit tests for Metric model validation
        - Test each metric type and its params
        - Test primary_entity property extraction from meta
        - Test validation edge cases

      labels:
        - stack:backend
        - type:feature
        - priority:high
      status: Refinement

    - title: "Implement dbt metrics YAML parser"
      description: |
        Create parser to read dbt metric YAML files and convert to Metric schema models.

        ## What needs to be built

        ### New Module: parsers/dbt_metrics.py

        **Main Parser Class**:
        ```python
        class DbtMetricParser(Parser):
            def parse_file(self, file_path: Path) -> list[Metric]:
                """Parse a single metric YAML file."""

            def parse_directory(self, directory: Path) -> list[Metric]:
                """Parse all metric files in directory."""

            def _validate_metric(self, metric: Metric, semantic_models: list[SemanticModel]) -> None:
                """Validate metric references valid measures and entities."""
        ```

        **Primary Entity Resolution**:
        ```python
        def resolve_primary_entity(
            metric: Metric,
            semantic_models: list[SemanticModel]
        ) -> str:
            """
            Determine primary entity for metric.

            Priority:
            1. Explicit meta.primary_entity
            2. Infer from denominator (ratio metrics only)
            3. Raise error - require explicit specification
            """
        ```

        **Dependency Extraction**:
        ```python
        def extract_measure_dependencies(metric: Metric) -> set[str]:
            """Extract all measure names referenced by metric."""
        ```

        ### File Discovery

        - Scan `metrics/` directory (configurable)
        - Support `*.yml` and `*.yaml` extensions
        - Handle nested directories
        - Skip invalid/malformed files with warnings

        ### Error Handling

        - Invalid YAML syntax → Clear error with line number
        - Missing required fields → Validation error
        - Unknown metric type → Error with supported types
        - Unreferenced measures → Warning
        - Missing primary_entity (when can't infer) → Error with guidance

        ## Why it's needed

        Enables reading dbt metric definitions so they can be converted to LookML.

        ## Technical scope

        Backend work in `src/dbt_to_lookml/parsers/`:
        - Create new dbt_metrics.py module
        - Extend base Parser interface if needed
        - Integrate with existing file reading utilities
        - Use Pydantic validation for data integrity

        ## Testing requirements

        - Unit tests for parsing each metric type
        - Test primary entity resolution (explicit, inferred, error cases)
        - Test dependency extraction
        - Test error handling for invalid YAML
        - Test directory scanning
        - Integration test with real metric files

      labels:
        - stack:backend
        - type:feature
        - priority:high
      status: Refinement

    - title: "Add cross-entity measure generation to LookMLGenerator"
      description: |
        Extend LookMLGenerator to generate measures that reference fields from other views.

        ## What needs to be built

        ### New Methods in LookMLGenerator

        **Metric to Measure Conversion**:
        ```python
        def _generate_metric_measure(
            self,
            metric: Metric,
            primary_model: SemanticModel,
            all_models: list[SemanticModel]
        ) -> dict[str, Any]:
            """
            Generate LookML measure dict from metric definition.

            Returns dict with:
            - name
            - type (always "number" for cross-entity)
            - sql (with ${view.measure} references)
            - required_fields (list of cross-view dependencies)
            - value_format_name
            - description
            - view_label
            - group_label
            """
        ```

        **SQL Generation by Metric Type**:
        ```python
        def _generate_ratio_sql(
            self,
            metric: RatioMetric,
            models: dict[str, SemanticModel]
        ) -> str:
            """Generate SQL for ratio metric: numerator / denominator"""
            # Returns: "1.0 * ${view.num} / NULLIF(${view.denom}, 0)"

        def _generate_derived_sql(
            self,
            metric: DerivedMetric,
            models: dict[str, SemanticModel]
        ) -> str:
            """Generate SQL for derived metric with expression evaluation"""
        ```

        **Required Fields Extraction**:
        ```python
        def _extract_required_fields(
            self,
            metric: Metric,
            primary_model: SemanticModel,
            all_models: list[SemanticModel]
        ) -> list[str]:
            """
            Identify which fields from other views this metric requires.

            Returns list like: ["rental_orders.rental_count", "users.user_count"]
            """
        ```

        ### Integration with View Generation

        Update `SemanticModel.to_lookml_dict()` or view generation:
        - Accept optional metrics parameter
        - Filter metrics by primary_entity matching this model
        - Generate measure dicts for owned metrics
        - Append to existing measures

        ### Measure Metadata

        All generated metric measures should include:
        - `label`: Human-readable name (from metric.label or titlecase name)
        - `description`: From metric.description
        - `view_label: " Metrics"` (with leading space for sorting)
        - `group_label`: Based on metric category or "Cross-Entity Performance"
        - `required_fields`: List of cross-view dependencies
        - `value_format_name`: Infer from metric type (percent for ratios, etc.)

        ## Why it's needed

        Core logic for converting dbt metrics to LookML measures with cross-view references.

        ## Technical scope

        Backend work in `src/dbt_to_lookml/generators/lookml.py`:
        - Add metric processing to LookMLGenerator
        - Generate measures with ${view.field} syntax
        - Handle all metric types (simple, ratio, derived)
        - Add required_fields parameter

        ## Testing requirements

        - Unit test for each metric type conversion
        - Test SQL generation for simple, ratio, derived metrics
        - Test required_fields extraction
        - Test measure metadata (labels, descriptions)
        - Test integration with view generation
        - Test view prefix handling in cross-view references

      labels:
        - stack:backend
        - type:feature
        - priority:high
      status: Refinement

    - title: "Update explore generation for metric requirements"
      description: |
        Modify explore join generation to expose measures required by cross-entity metrics.

        ## What needs to be built

        ### Explore Analysis

        **Identify Metric Requirements**:
        ```python
        def _identify_metric_requirements(
            self,
            base_model: SemanticModel,
            metrics: list[Metric],
            all_models: list[SemanticModel]
        ) -> dict[str, set[str]]:
            """
            For a given explore base model, determine which measures from joined views
            are needed by cross-entity metrics.

            Returns: {
                "rental_orders": {"rental_count", "total_revenue"},
                "users": {"user_count"}
            }
            """
        ```

        ### Join Field Exposure

        **Current Logic** (from DTL-001):
        ```python
        join["fields"] = [f"{target_view_name}.dimensions_only*"]
        ```

        **Enhanced Logic**:
        ```python
        # Base: dimensions only
        fields = [f"{target_view_name}.dimensions_only*"]

        # Add required measures for cross-entity metrics
        if target_view_name in metric_requirements:
            for measure_name in metric_requirements[target_view_name]:
                fields.append(f"{target_view_name}.{measure_name}")

        join["fields"] = fields
        ```

        ### Example Output

        **Before** (DTL-001):
        ```lookml
        join: rental_orders {
          fields: [rental_orders.dimensions_only*]
        }
        ```

        **After** (with metrics):
        ```lookml
        join: rental_orders {
          fields: [
            rental_orders.dimensions_only*,
            rental_orders.rental_count,
            rental_orders.total_revenue
          ]
        }
        ```

        ### Edge Cases

        - Base explore view measures: Don't add to required_fields (same view)
        - Multi-hop joins: Ensure intermediate joins also expose required measures
        - No metrics using a join: Keep dimensions_only* only
        - Measure already exposed: Don't duplicate in fields list

        ## Why it's needed

        Makes cross-view measures available in explores so required_fields can reference them.

        ## Technical scope

        Backend work in `src/dbt_to_lookml/generators/lookml.py`:
        - Modify `_build_join_graph()` method
        - Add metric requirements analysis
        - Update fields parameter generation
        - Maintain backward compatibility with non-metric generation

        ## Testing requirements

        - Test join fields with no metrics (dimensions_only only)
        - Test join fields with metrics requiring that view's measures
        - Test multiple measures from same view
        - Test multi-hop join scenarios
        - Test that base view measures are not in required_fields
        - Integration test: verify full explore with metric requirements

      labels:
        - stack:backend
        - type:feature
        - priority:high
      status: Refinement

    - title: "Add entity connectivity validation"
      description: |
        Implement validation to ensure all measures required by a metric are reachable via join graph from the primary entity.

        ## What needs to be built

        ### Join Graph Analysis

        **Build Reachability Map**:
        ```python
        def build_join_graph(
            base_model: SemanticModel,
            all_models: list[SemanticModel],
            max_hops: int = 2
        ) -> dict[str, int]:
            """
            Build a map of which semantic models are reachable from base_model.

            Returns: {
                "rental_orders": 0,  # Base model
                "users": 1,          # Direct join (1 hop)
                "searches": 1,       # Direct join (1 hop)
                "sessions": 2,       # Multi-hop via searches (2 hops)
            }
            """
        ```

        ### Metric Validation

        **Validate Connectivity**:
        ```python
        def validate_metric_connectivity(
            metric: Metric,
            primary_model: SemanticModel,
            all_models: list[SemanticModel]
        ) -> ValidationResult:
            """
            Verify all measures required by metric are reachable from primary_model.

            Raises ValidationError with helpful message if not reachable:
            - Which measure is unreachable
            - Which model contains that measure
            - Suggestion to change primary_entity or use derived table
            """
        ```

        ### Validation Checks

        1. **Primary entity exists**: Entity name is valid in some semantic model
        2. **Measures exist**: All referenced measures exist in semantic models
        3. **Measures reachable**: All measure models are in join graph
        4. **Join depth**: All required models are within 2 hops (dbt limit)

        ### Error Messages

        **Example 1: Unreachable measure**
        ```
        ValidationError: Metric 'conversion_rate' cannot be generated.

        Primary Entity: user_sk
        Unreachable Measure: session_count (from sessions model)

        The 'sessions' model is not reachable from 'users' via foreign key relationships.

        Suggestions:
        - Change primary_entity to an entity that connects both models
        - Use a derived table approach for this metric
        - Add entity relationship to connect users and sessions
        ```

        **Example 2: Missing primary entity**
        ```
        ValidationError: Metric 'search_conversion_rate' requires explicit primary_entity.

        The metric references measures from multiple entities:
        - rental_count (from rental_orders.rental_sk)
        - search_count (from searches.search_sk)

        Specify which entity should own this metric in the meta block:

        meta:
          primary_entity: search  # or 'rental'
        ```

        ### Integration Points

        - Run during metric parsing (early validation)
        - Run before LookML generation (final check)
        - Provide `--strict` mode for failing on any validation warning

        ## Why it's needed

        Prevents generating invalid LookML that would error at query time. Provides clear feedback to users about metric configuration issues.

        ## Technical scope

        Backend work in `src/dbt_to_lookml/`:
        - Add validation module or extend existing
        - Integrate with metric parser
        - Integrate with generator
        - Clear error messages with actionable suggestions

        ## Testing requirements

        - Test valid metric (all measures reachable)
        - Test unreachable measure (model not in join graph)
        - Test missing primary entity
        - Test invalid primary entity name
        - Test measure doesn't exist
        - Test multi-hop reachability
        - Test max hop limit (3+ hops should warn/error)

      labels:
        - stack:backend
        - type:feature
        - priority:medium
      status: Refinement

    - title: "Add comprehensive tests for cross-entity metrics"
      description: |
        Implement unit, integration, and golden tests for cross-entity metric generation.

        ## What needs to be built

        ### Unit Tests

        **Metric Schema Tests** (`test_schemas.py`):
        - Test Metric model validation (all types)
        - Test primary_entity property extraction
        - Test MetricTypeParams variants
        - Test validation edge cases

        **Metric Parser Tests** (`test_dbt_metric_parser.py`):
        - Test parse_file for each metric type
        - Test parse_directory with multiple files
        - Test primary entity resolution (explicit, inferred, error)
        - Test dependency extraction
        - Test error handling (invalid YAML, missing fields)
        - Test nested directories

        **Measure Generation Tests** (`test_lookml_generator.py`):
        - Test _generate_metric_measure for each type
        - Test SQL generation (ratio, derived, simple)
        - Test required_fields extraction
        - Test cross-view reference formatting
        - Test view prefix handling
        - Test measure metadata (labels, descriptions)

        **Explore Enhancement Tests** (`test_lookml_generator.py`):
        - Test join fields without metrics (dimensions_only only)
        - Test join fields with metric requirements
        - Test multiple metrics requiring same view
        - Test no duplicate measures in fields list

        **Validation Tests** (`test_validation.py`):
        - Test entity connectivity validation
        - Test reachability checks
        - Test error messages for common issues
        - Test multi-hop join validation

        ### Integration Tests

        **End-to-End Metric Generation** (`test_cross_entity_metrics.py`):
        - Create semantic model fixtures (rental_orders, searches, users)
        - Create metric fixtures (search_conversion_rate, revenue_per_user)
        - Parse metrics and semantic models
        - Generate LookML
        - Verify generated measures in correct views
        - Verify required_fields present
        - Verify join fields expose required measures
        - Validate generated LookML syntax

        ### Golden Tests

        **Expected Output Files**:
        - `expected_searches_with_metrics.view.lkml`: Searches view with cross-entity measure
        - `expected_explores_with_metrics.lkml`: Explores with enhanced join fields

        Compare generated output against golden files.

        ### Test Fixtures

        **Semantic Models**:
        - `sem_rental_orders.yml`: Fact table with measures
        - `sem_searches.yml`: Fact table with measures and foreign key to users
        - `sem_users.yml`: Dimension table with measures

        **Metrics**:
        - `search_conversion.yml`: Ratio metric (search as primary)
        - `revenue_per_user.yml`: Ratio metric (user as primary)
        - `engagement_score.yml`: Derived metric with 3 entities

        ### Coverage Target

        - Overall: 95%+ branch coverage
        - New code: 100% coverage
        - All metric types tested
        - All error paths tested
        - All validation scenarios tested

        ## Why it's needed

        Ensures cross-entity metric feature works correctly and maintains quality standards.

        ## Technical scope

        Testing work in `src/tests/`:
        - Unit tests in `unit/`
        - Integration tests in `integration/`
        - Golden tests in `test_golden.py`
        - Test fixtures in appropriate directories

        ## Testing requirements

        - All tests must pass
        - Coverage target must be met
        - Tests must follow existing patterns (arrange-act-assert)
        - Use pytest fixtures appropriately
        - Clear test names describing what is tested

      labels:
        - stack:backend
        - type:testing
        - priority:medium
      status: Refinement
